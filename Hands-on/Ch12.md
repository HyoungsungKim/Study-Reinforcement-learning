# Ch12 The Actor-Critic Method

REINFORCE and policy gradient are worked well in small environmnet, however these are not worked in complicated environment like Atari-pong

## Variance reduction

In statistics, variance is the expected square deviation of a random variable from the expected value of that variable.
$$
Va[x] = \mathbb{E}[(x-\mathbb{E}[x])^2]
$$

- Variance shows us how far values are dispersed from the mean.

$$
\nabla J \approx \mathbb{E}[Q(s,a)\nabla \log{\pi(a|s)}]
$$

- Q(s,a) : Scaling factor -> Specifies how much we want to increase or decrease the probability of the action taken in the particular state.
- In an attempt to increase REINFORCE stability, ***we subtracted the mean reward from the gradient scale.***
  - To understand why this helped, let's consider the very simple scenario of an optimization step on which we have three actions with different total discounted rewards: $$Q_1$$, $$Q_2$$, and $$Q_3$$. Now let's consider the policy gradient with regard to the relative values of those $$Q_s$$.