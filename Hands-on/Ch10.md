# Ch10 Stocks Trading Using RL

## Problem statements and key decisions

As you already know, to formulate RL problems, three things are needed:

- Observation of the environment
- Possible actions
- A reward system.

In previous chapters, all three were already given to us, and the internal machinery of the environment was hidden. 

----

In our case, we will implement the basic trading agent in its simplest form. The ***observation*** will include the following information:

- N past bars, where each has open, high, low, and close prices
- An indication that the share was bought some time ago (only one share at a time will be possible)
- Profit or loss that we currently have from our current position (the share bought)

At every step, after every minute's bar, the agent can take one of the following ***actions***:

- ***Do nothing:*** skip the bar without taking an action
- ***Buy a share:*** if the agent has already got the share, nothing will be bought; otherwise, we will pay the commission, which is usually some small percentage of the current price
- ***Close the position:*** if we do not have a previously purchased share, nothing will happen; otherwise, we will pay the commission for the trade

The ***reward*** that the agent receives can be expressed in various ways. On the one hand, we can split the reward into multiple steps during our ownership of the share.

- In that case, the reward on every step will be equal to the last bar's movement. On the other hand, the agent will receive the reward only after the close action and receive the full reward at once.
- At first sight, both variants should have the same final result, but maybe with different convergence speeds. However, in practice, the difference could be dramatic.